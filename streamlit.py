"""
Application Streamlit pour l'Assistant Juridique Grok-3

Ce module fournit une interface web interactive permettant aux utilisateurs
de poser des questions juridiques √† Grok-3 et de visualiser les r√©ponses
dans un format de chat convivial avec streaming en temps r√©el.

Auteur: NAKIB Wassil
Version: 0.2 - Adapt√© pour le streaming Grok
Date: 2025-06-26
"""

import streamlit as st
from grok3_utils import call_grok
import time
from typing import Any, List, Dict, Optional


# ================================
# CONFIGURATION ET CONSTANTES
# ================================

PAGE_CONFIG = {
    "page_title": "Assistant Juridique Grok-3",
    "page_icon": "‚öñÔ∏è",
    "layout": "wide"
}

# Mod√®les Grok disponibles
AVAILABLE_MODELS = {
    "Grok-3 Latest (Recommand√©)": "grok-3-latest",
    "Grok-3 Mini": "grok-3-mini", 
    "Grok-3 Fast": "grok-3-fast",
    "Grok-3 Mini Fast": "grok-3-mini-fast"
}

DEFAULT_MODEL = "grok-3-latest"

CUSTOM_CSS = """
<style>
    .stTextArea textarea {
        font-size: 16px;
        border-radius: 10px;
    }
    
    .stButton button {
        font-weight: bold;
        border-radius: 10px;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    
    .user-message {
        background-color: #e8f4fd;
    }
    
    .assistant-message {
        background-color: #f0f8f0;
    }
    
    .legal-highlight {
        background-color: #fff3cd;
        border-left: 4px solid #ffc107;
        padding: 0.5rem;
        margin: 0.5rem 0;
    }
    
    .streaming-indicator {
        color: #1f77b4;
        font-style: italic;
    }
    
    .metrics-container {
        background-color: #f8f9fa;
        border-radius: 8px;
        padding: 10px;
        margin: 10px 0;
    }
</style>
"""

# ================================
# FONCTIONS DE CONFIGURATION
# ================================

def configure_streamlit_page() -> None:
    """Configure les param√®tres de base de la page Streamlit."""
    st.set_page_config(**PAGE_CONFIG)

def apply_custom_styling() -> None:
    """Applique le CSS personnalis√© √† l'interface Streamlit."""
    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

# ================================
# FONCTIONS D'INITIALISATION
# ================================

def initialize_session_state() -> None:
    """Initialise les variables de session Streamlit n√©cessaires."""
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    
    if 'current_query' not in st.session_state:
        st.session_state.current_query = ""
    
    if 'uploaded_files' not in st.session_state:
        st.session_state.uploaded_files = []
    
    if 'last_response_metrics' not in st.session_state:
        st.session_state.last_response_metrics = None
    
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = DEFAULT_MODEL

# ================================
# FONCTIONS D'INTERFACE UTILISATEUR
# ================================

def render_page_header() -> None:
    """Affiche l'en-t√™te principal de la page."""
    st.title("‚öñÔ∏è Assistant Juridique Grok-3")
    st.markdown("*Posez vos questions juridiques √† un expert IA avec streaming en temps r√©el*")
    st.markdown("---")

def render_sidebar_information() -> None:
    """Affiche les informations et instructions dans la barre lat√©rale."""
    with st.sidebar:
        # === SECTION CONFIGURATION MOD√àLE (DROPDOWN ICI) ===
        st.header("üîß Configuration du Mod√®le")
        
        # S√©lecteur de mod√®le - CECI EST LE DROPDOWN
        model_display_names = list(AVAILABLE_MODELS.keys())
        current_model_display = None
        
        # Trouver le nom d'affichage du mod√®le actuel
        for display_name, model_code in AVAILABLE_MODELS.items():
            if model_code == st.session_state.selected_model:
                current_model_display = display_name
                break
        
        # Si le mod√®le actuel n'est pas trouv√©, utiliser le premier
        if current_model_display is None:
            current_model_display = model_display_names[0]
            st.session_state.selected_model = AVAILABLE_MODELS[current_model_display]
        
        # DROPDOWN SELECTOR - CECI EST L'√âL√âMENT INTERACTIF
        selected_display_name = st.selectbox(
            "ü§ñ Choisissez le mod√®le Grok:",
            options=model_display_names,
            index=model_display_names.index(current_model_display),
            key="model_selector",
            help="Diff√©rents mod√®les avec des performances et vitesses variables"
        )
        
        # Mettre √† jour le mod√®le s√©lectionn√©
        new_model = AVAILABLE_MODELS[selected_display_name]
        if new_model != st.session_state.selected_model:
            st.session_state.selected_model = new_model
            st.success(f"‚úÖ Mod√®le chang√© vers: **{new_model}**")
            st.rerun()
        
        # Informations sur le mod√®le s√©lectionn√©
        model_info = get_model_info(st.session_state.selected_model)
        st.info(model_info)
        
        st.markdown("---")
        
        # === SECTION INFORMATIONS ===
        st.header("‚ÑπÔ∏è Informations sur l'Assistant")
        
        # MAINTENANT LE MOD√àLE AFFICH√â EST DYNAMIQUE
        st.markdown(f"**üîß Mod√®le utilis√© :** {st.session_state.selected_model}")
        st.markdown("**‚öñÔ∏è Sp√©cialit√© :** Droit et questions juridiques")
        st.markdown("**üåê Langue :** Fran√ßais")
        st.markdown("**üîÑ Mode :** Streaming temps r√©el")
        st.markdown("**üìÑ Formats support√©s :** PDF, TXT")
        
        st.markdown("---")
        
        # M√©triques de la derni√®re r√©ponse
        if st.session_state.last_response_metrics:
            st.header("üìä Derni√®res M√©triques")
            metrics = st.session_state.last_response_metrics
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Caract√®res", metrics.get('chars_count', 0))
            with col2:
                st.metric("Citations", metrics.get('citations_count', 0))
            
            if metrics.get('citations'):
                with st.expander("üîó Citations"):
                    for i, citation in enumerate(metrics['citations'][:5], 1):
                        st.write(f"{i}. {citation[:100]}...")
        
        st.markdown("---")
        
        # Exemples de questions
        st.header("üí° Exemples de Questions")
        example_questions = [
            "Quelles sont les obligations d'un employeur en mati√®re de s√©curit√© au travail ?",
            "Comment contester un PV de stationnement ?",
            "Quels sont les droits d'un locataire en cas de nuisances ?",
            "Comment cr√©er une SARL en France ?",
            "Que faire en cas de litige avec un voisin ?"
        ]
        
        for question in example_questions:
            if st.button(f"üìù {question[:50]}...", key=f"example_{hash(question)}", help=question):
                st.session_state.current_query = question
                st.rerun()
        
        st.markdown("---")
        
        # Guide des mod√®les
        with st.expander("üìñ Guide des Mod√®les"):
            st.markdown("""
            **üî• Grok-3 Latest**: Mod√®le le plus avanc√©, r√©ponses les plus compl√®tes
            
            **‚ö° Grok-3 Fast**: √âquilibre entre qualit√© et vitesse
            
            **üéØ Grok-3 Mini**: Version all√©g√©e, plus rapide
            
            **üöÄ Grok-3 Mini Fast**: Le plus rapide, pour des r√©ponses courtes
            """)


def get_model_info(model_code: str) -> str:
    """Retourne les informations sur un mod√®le donn√©."""
    model_descriptions = {
        "grok-3-latest": "üî• Mod√®le le plus avanc√© - R√©ponses d√©taill√©es et compl√®tes",
        "grok-3-fast": "‚ö° √âquilibre optimal - Qualit√© et vitesse",
        "grok-3-mini": "üéØ Version compacte - R√©ponses concises et rapides", 
        "grok-3-mini-fast": "üöÄ Ultra-rapide - Id√©al pour des questions simples"
    }
    return model_descriptions.get(model_code, "‚ÑπÔ∏è Mod√®le Grok standard")

def render_conversation_display() -> None:
    """Affiche l'historique de conversation dans un format chat."""
    if st.session_state.conversation_history:
        for message in st.session_state.conversation_history:
            display_single_message(message)

def handle_chat_input() -> None:
    """G√®re l'entr√©e de chat utilisateur et traite les messages."""
    # Utiliser la query stock√©e en session si disponible
    default_value = st.session_state.current_query
    
    user_input = st.chat_input(
        placeholder="Posez votre question juridique ici...",
        key="legal_chat_input"
    )
    
    # Si on a une query en session, l'utiliser et la nettoyer
    if st.session_state.current_query and not user_input:
        user_input = st.session_state.current_query
        st.session_state.current_query = ""
    
    if user_input:
        handle_user_query_submission(user_input)

# ================================
# FONCTIONS DE GESTION DES MESSAGES
# ================================

def add_message_to_history(role: str, content: str, metadata: Optional[Dict] = None) -> None:
    """Ajoute un message √† l'historique de conversation."""
    message = {
        "role": role,
        "content": content,
        "timestamp": time.strftime("%H:%M:%S"),
        "metadata": metadata or {}
    }
    st.session_state.conversation_history.append(message)

def clear_conversation_history() -> None:
    """Efface compl√®tement l'historique de conversation."""
    st.session_state.conversation_history = []
    st.session_state.last_response_metrics = None

def display_single_message(message: Dict[str, Any]) -> None:
    """Affiche un message individuel dans l'interface chat."""
    role_emoji = "üë§" if message["role"] == "user" else "‚öñÔ∏è"
    role_name = "Vous" if message["role"] == "user" else "Assistant Juridique"
    
    with st.chat_message(message["role"]):
        st.markdown(f"**{role_emoji} {role_name}** - {message['timestamp']}")
        st.markdown(message["content"])
        
        # Afficher les m√©tadonn√©es si disponibles
        if message.get("metadata") and message["role"] == "assistant":
            metadata = message["metadata"]
            if metadata.get("citations_count", 0) > 0:
                st.caption(f"üìö {metadata['citations_count']} citations trouv√©es")

def render_conversation_controls() -> None:
    """Affiche les contr√¥les de gestion de conversation."""
    if st.session_state.conversation_history:
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            if st.button("üóëÔ∏è Effacer l'historique", type="secondary"):
                clear_conversation_history()
                st.rerun()
        
        with col2:
            if st.button("üìÑ Exporter la conversation", type="secondary"):
                export_conversation_history()

def export_conversation_history() -> None:
    """Exporte l'historique de conversation en format texte."""
    if not st.session_state.conversation_history:
        st.warning("Aucune conversation √† exporter.")
        return
    
    export_text = "=== HISTORIQUE CONVERSATION ASSISTANT JURIDIQUE ===\n\n"
    
    for message in st.session_state.conversation_history:
        role_name = "UTILISATEUR" if message["role"] == "user" else "ASSISTANT"
        export_text += f"[{message['timestamp']}] {role_name}:\n"
        export_text += f"{message['content']}\n\n"
        export_text += "-" * 50 + "\n\n"
    
    st.download_button(
        label="üíæ T√©l√©charger l'historique",
        data=export_text,
        file_name=f"conversation_juridique_{time.strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain"
    )

# ================================
# FONCTIONS DE TRAITEMENT GROK-3
# ================================

def enhance_user_query(query: str, has_file: bool = False) -> str:
    """Am√©liore la query utilisateur avec du contexte juridique."""
    if has_file:
        enhanced_query = f"""
CONTEXTE: Question juridique avec document joint.
QUESTION: {query}

Veuillez analyser cette question juridique en tenant compte du document fourni.
Donnez une r√©ponse d√©taill√©e et structur√©e avec :
1. Une analyse claire de la situation
2. Les r√©f√©rences l√©gales pertinentes
3. Les implications pratiques
4. Les conseils d'action si appropri√©
"""
    else:
        enhanced_query = f"""
CONTEXTE: Question juridique.
QUESTION: {query}

Veuillez fournir une r√©ponse juridique claire et d√©taill√©e avec :
1. Une explication du cadre juridique applicable
2. Les r√©f√©rences l√©gales pertinentes
3. Les implications et cons√©quences
4. Des conseils pratiques si appropri√©
"""
    
    return enhanced_query

def handle_user_query_submission(query: str) -> None:
    """G√®re la soumission d'une question utilisateur avec streaming."""
    if not query.strip():
        st.warning("‚ö†Ô∏è Veuillez entrer une question avant d'envoyer.")
        return
    
    # V√©rification de fichiers joints
    has_uploaded_file = bool(st.session_state.uploaded_files)
    
    # Ajout de la question utilisateur √† l'historique
    display_query = query
    if has_uploaded_file:
        file_name = st.session_state.uploaded_files[0].name
        display_query += f"\n\nüìÑ *Document joint: {file_name}*"
    
    add_message_to_history("user", display_query)
    
    # Affichage de la question utilisateur
    display_single_message({
        "role": "user", 
        "content": display_query,
        "timestamp": time.strftime("%H:%M:%S"),
        "metadata": {}
    })
    
    # Pr√©paration de la requ√™te am√©lior√©e
    enhanced_query = enhance_user_query(query, has_uploaded_file)
    
    # Streaming avec Grok-3
    with st.chat_message("assistant"):
        st.markdown(f"**‚öñÔ∏è Assistant Juridique** - {time.strftime('%H:%M:%S')}")
        
        # Container pour le streaming
        response_container = st.empty()
        status_container = st.empty()
        complete_response = ""
        final_result = None
        
        try:
            # Indicateur de streaming
            status_container.markdown("üîÑ *G√©n√©ration de la r√©ponse en cours...*")
            
            # Streaming en temps r√©el avec le g√©n√©rateur
            for item in call_grok(enhanced_query):
                if isinstance(item, dict):
                    # C'est le r√©sultat final
                    if item.get("type") == "final_result":
                        final_result = item
                        status_container.markdown("‚úÖ *R√©ponse g√©n√©r√©e avec succ√®s*")
                        break
                    elif item.get("type") == "error":
                        # Gestion d'erreur
                        error_msg = f"‚ùå Erreur: {item['message']}"
                        response_container.error(error_msg)
                        status_container.empty()
                        add_message_to_history("assistant", error_msg)
                        return
                else:
                    # C'est un chunk de texte
                    complete_response += item
                    response_container.markdown(complete_response)
            
            # Nettoyage du statut
            status_container.empty()
            
            # Traitement du r√©sultat final
            if final_result:
                # Stocker les m√©triques pour la sidebar
                st.session_state.last_response_metrics = {
                    'chars_count': len(final_result.get('complete_text', complete_response)),
                    'citations_count': len(final_result.get('citations', [])),
                    'citations': final_result.get('citations', [])
                }
                
                # Affichage des m√©triques en bas de la r√©ponse
                if final_result.get('citations'):
                    with st.expander(f"üìö Citations trouv√©es ({len(final_result['citations'])})", expanded=False):
                        for i, citation in enumerate(final_result['citations'], 1):
                            st.write(f"{i}. {citation}")
                
                # Ajout √† l'historique avec m√©tadonn√©es
                metadata = {
                    'citations_count': len(final_result.get('citations', [])),
                    'chars_count': len(complete_response)
                }
                add_message_to_history("assistant", complete_response, metadata)
            else:
                # Pas de r√©sultat final re√ßu
                add_message_to_history("assistant", complete_response)
                
        except Exception as error:
            error_msg = f"‚ùå Erreur lors du streaming: {str(error)}"
            response_container.error(error_msg)
            status_container.empty()
            add_message_to_history("assistant", error_msg)

# ================================
# FONCTION UTILITAIRE
# ================================

def render_application_footer() -> None:
    """Affiche le pied de page de l'application."""
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #666; padding: 20px;'>
            ‚öñÔ∏è Propuls√© par <strong>Grok-3</strong> | 
            üé® Interface <strong>Streamlit</strong> | 
            üìö Assistant Juridique Intelligent | 
            üîÑ <strong>Streaming Temps R√©el</strong>
        </div>
        """, 
        unsafe_allow_html=True
    )

# ================================
# FONCTION PRINCIPALE
# ================================

def main() -> None:
    """Fonction principale de l'application Streamlit."""
    # Configuration et initialisation
    configure_streamlit_page()
    apply_custom_styling()
    initialize_session_state()
    
    # Rendu de l'interface
    render_page_header()
    render_sidebar_information()
    
    # Affichage de la conversation existante
    render_conversation_display()
    
    # Gestion de l'entr√©e chat
    handle_chat_input()
    
    # Contr√¥les de conversation
    render_conversation_controls()
    
    # Pied de page
    render_application_footer()

# ================================
# POINT D'ENTR√âE
# ================================

if __name__ == "__main__":
    main()